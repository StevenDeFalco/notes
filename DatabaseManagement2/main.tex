% A note-taking template by Steven DeFalco
% github.com/StevenDeFalco/notes

\documentclass{article}

% import note styles
\usepackage{../styles}

% Heading information
\title{CS562: Database Management Systems II Notes}
\author{Steven DeFalco}
\date{Spring 2024}


\begin{document}


\maketitle
\tableofcontents
\newpage


\section{Indexing}

Indexing methods are used to speed up access to desired data. A \define{search key} is an attribute used to look up records in a file. An \define{index file} consists of records (called \bold{index entries}) of the form. Index files are typically much smaller than the original file. There are two basic kinds of indices:
\begin{itemize}
  \item \bold{Ordered indices}: search keys are stored in sorted order 
  \item \bold{Hash indices}: search keys are distributed uniformly across \emph{buckets} using a \emph{hash function}
\end{itemize}

\begin{remark}
  When \emph{optimizing} in database queries, the goal is to have a small search space. 
\end{remark}

In an \define{ordered index}, index entries are stored sorted on the search key value. In a sequentially ordered file, the \define{primary index} is the index whose search key specifies the sequential order of the file; the search key of a primary index is usually but not necessarily the primary key. The \define{secondary index} is an index whose key specifies an order different from the sequential order of the file (also called non-clustering index). An \define{index-sequential file} is an ordered sequential file with a primary index. 

A \define{dense index} is where an index record appears for every search-key value in the file. \define{Sparse index} contains index records for only some search-key values. To locate a record with search-key value $K$ we: 
\begin{enumerate}
  \item Find index record with largest search-key value $<K$ 
  \item Search file sequentially starting at the record to which the index record points
\end{enumerate}

\begin{remark}
  Sparse index must be primary index
\end{remark}
Compared to dense indices, sparse indices have less space and less maintenance overhead for insertions and deletions. However, they are generally slower than dense index for locating records. a record with search-key value $K$ we: 
\begin{enumerate}
  \item Find index record with largest search-key value $<K$ 
  \item Search file sequentially starting at the record to which the index record points
\end{enumerate}

\begin{remark}
  Sparse index must be primary index
\end{remark}
Compared to dense indices, sparse indices have less space and less maintenance overhead for insertions and deletions. However, they are generally slower than dense index for locating records. \\ 

If primary index does not fit in memory, access becomes expensive. A solution to this is to treat primary index kept on disk as a sequential file and construct a sparse index on it. The outer index is a sparse index of primary index. The inner index is the primary index file. If even out index is too large to fit in main memory, yet another level of index can be created and so on. Indices at all levels must be updated on insertion or deletion from the file. 

\subsection{Index Updates}

\subsubsection{Deletion} 

If the deleted record was the only record in the file with its particular search-key value, the seark-key is deleted from the index also. For singl e-level index deletion. 
\begin{itemize}
  \item Dense indices---deleetion of search-key 
  \item Sparse indices--- 
    \begin{itemize}
      \item If an entry for the search key exists in the index, it is deleted by replacing the entry in teh index with the next search-key value in the file 
      \item If the next search-key value already has an index entry, the entry is deleted instead of being replaced
    \end{itemize}
\end{itemize}

\subsubsection{Insertion}

In single-level index insertion: 
\begin{itemize}
  \item Perform a lookup using the searh-key value appearing in the record to be inserted. 
  \item Dense indices---if the search-key value does not appear in the index, insert it 
  \item sparse indices---if index stores an entry for each block of the file, no chnage needs to be made to the index unless a new block is created. If a new block is created, the first search-key value appearing in the new block is inserted into the index. 
\end{itemize}
In multilevel insertion, algorithms are simple extensiosn of the single-level algorithms. 

Indices offer substantial benefits when searching for records, but updating indices imposes overhead on database modification---when a file is modified, every index on the file must be updated. Sequential scan using primary index is efficient, but a sequential scan using a second index is expensive. 

\section{B+ Tree Index Files}

B$^{+}$-tree indices are an alternative to indexed-sequential files. Some disadvantages of indexed-sequential files are that performance degrades as the file grows (since many overflow blocks get created) and that periodic reorganization of the entire file is required. Advantages of B$^{+}$-tree index files are: 
\begin{itemize}
  \item automatically reorganizes itself with small, local changes in the face of insertions and deletions 
  \item Reorganization of entire file is not required to maintain performance
\end{itemize}
One minor disadvantage of B$^{+}$-trees is the extra insertion and deletion overhead (space overhead); however, the advantages outweigh the disadvantages and thus this structure is used extensively. \\ 

A B$^{+}$-tree is a rooted tree satisfying the following properties: 
\begin{itemize}
  \item All paths from root to leaf are of the same length 
  \item Each node that is not a root or a leaf has between $\ceil{n/2}$ and $n$ children 
  \item A leaf node has between $\ceil{(n-1)/2}$ and $n-1$ values 
  \item Special cases\dots 
    \begin{itemize}
      \item If the root is not a leaf, it has at least 2 children. 
      \item If the root is a leaf (that is, there are no other nodes in the tree), it can have between $0$ and $(n-1)$ values. 
    \end{itemize}
\end{itemize}

\subsection{Types of nodes in B$^{+}$-trees}

The following are properties of a \bold{leaf node}: 
\begin{itemize}
  \item For $i=1,2, \dots , n-1$, pointer $P_i$ either points to a file record with search-key value $K_i$, or to a bucket of pointers to file records, each record having search-key value $K_i$. Only need bucket structure if search-key does not form a primary key. 
  \item If $L_i , L_j$ are leaf nodes and $i < j$, $L_j$'s search-key values are less than $L_j$'s search-key values 
  \item $P_n$ points to next leaf node in search-key order 
\end{itemize}

\bold{Nonleaf nodes} form a multi-level sparse index on the leaf nodes. For a non-leaf node with $m$ pointers: 
\begin{itemize}
  \item All the search-keys in the subtree to which $P_1$ points are less than $K_{1}$ 
  \item For $2 \leq i \leq n - 1$, all the search-keys in the substree to which $P_i$ points have values greater than or equal to $K_{i-1}$ and less than $K_i$ 
  \item All the search-keys in the subtree to which $P_n$ points have values greater than or equal to $K_{n-1}$
\end{itemize}

Since the inter-node connections are done by pointers, \emph{logically} close blocks need not be \emph{physically} close. The non-leaf levels of the B$^{+}$-tree form a hierarchy of sparse indices. The B$^{+}$-tree contains a relatively small number of levels; level below root has at least $2 \times \ceil{n/2}$ values. If there are $K$ search-key values in the file, the tree height is no more than $\ceil{\textrm{log}_{\ceil{n/2}}(K)}$. Insertions and deletions to the main file can be handled efficiently, as the index can be restructured in logarithmic time. 

\subsection{Queries on a B$^{+}$-tree}

Find all records of a search-key value of $k$. 
\begin{enumerate}
  \item $N=\textrm{root}$ 
  \item Repeat 
    \begin{enumerate}
      \item Examine $N$ for the smallest search-key value $>k$. 
      \item If such a value exists, assume it is $K_i$. THen set $N=P_i$ 
      \item Otherwise $k \geq K_{n-1}$. Set $N=P_n$
    \end{enumerate}
    Until $N$ is a leaf node 
  \item If for some $i$, key $K_i = k$ follow pointer $P_i$ to the desired record or bucket. 
  \item Else no record with search-key value $k$ exists
\end{enumerate}

\subsection{Updates on B$^{+}$-trees}

\subsubsection{Insertion}

To perform insertion on a B$^{+}$-tree\dots 
\begin{enumerate}
  \item Find the leaf node in which the search-key value would appear 
  \item If the search-key value is already present in the leaf node 
    \begin{enumerate}
      \item Add record to the file 
      \item If necessary add a pointer to the bucket 
    \end{enumerate}
  \item If the search-key value is not present, then  
    \begin{enumerate}
      \item Add the record to the main file (and create a bucket if necessary) 
      \item If there is room in the leaf node, insert (key-value, pointer) pair in the leaf node 
      \item Otherwise, split the node (along with new (key-value, pointer) entry) 
    \end{enumerate}
\end{enumerate}
To split a leaf node\dots 
\begin{itemize}
  \item Take the $n$ (search-key value, pointer) pairs (including the one being inserted) in sorted order. Place the first $\ceil{n/2}$ in the original node, and the rest in a new node. 
  \item let the new node by $p$, and let $k$ be the least key value in $p$. Insert $(k,p)$ in the parent of the node being split. 
  \item If the parent is full, split it and \bold{propagate} the split further up. 
\end{itemize}
Splitting of nodes proceeds upwards until a node that is not full is found. In the wrost case, the root node may be split increasing the height of the tree by 1. \\ 

To split a non-leaf node: when inserting $(k,p)$ into an already full internal node $N$ 
\begin{itemize}
  \item Copy $N$ to an in-memory area $M$ with space for $n+1$ pointers and $n$ keys 
  \item Insert $(k,p)$ into $M$ 
  \item Copy from $M$ back into node $N$ 
  \item Copy from $M$ into newly allocated node $N'$ 
  \item Insert $(K_{\ceil{n/2}}, N')$ into parent $N$
\end{itemize}

\subsubsection{Deletion}

To perform a deletion in a B$^{+}$-tree\dots 
\begin{itemize}
  \item Find the record to be deleted, and remove it from the main file and from the bucket (if present)
  \item Remove (search-key value, pointer) from the leaf node if there is no bucket or if the bucket has become empty 
  \item If the node has too few entries due to the removal, and the entries in the node and a sibling fit into a single node, then \emph{merge siblings}: 
    \begin{itemize}
      \item Insert all the search-key values in the two nodes into a single node (the one on the left), and delete the other node 
      \item Delete the pair $(K_{i-1}, P_{i})$, where $P_i$ is the pointer to the deleted node, from its parent, recursively using the above procedure. 
    \end{itemize}
  \item Otherwise, if the node has too few entries due to the removal, but the entries in the node and a sibling do not fit into a single node, then \emph{redistribute pointers}: 
    \begin{itemize}
      \item Redistribute the pointers between the node and a sibling such that both have more than the minimum number of entries 
      \item Update the corresponding search-key value in the parent of the node
    \end{itemize}
  \item The node deletions may cascade upwards until a node which has $\ceil{n/2|}$ or more pointers is found 
  \item If the root node has only one pointer after deletion, it is deleted and the sole child becomes the root. 
\end{itemize}

\subsubsection{Indexing}

Variable lenght strings are used as the keys: use space utilization as criterion for splitting, not number of pointers. \define{Prefix compression} is that key values at internal nodes can be prefixes of the full key. For this, must keep enough chraracters to distinguish entries in the subtrees separated by the key value. Keys in the leaf nodes can be compressed by sharing common prefixes. \\ 

\subsubsection{B-Tree Index Files}

B-Tree index files are similar to B$^{+}$-trees, but B-tree allows search-key values to appear only once; eliminates redundant storage of search keys. Search keys in nonleaf nodes appear nowhere else in the B-tree; an additional pointer field for each search key in a nonleaf node must be included. Some advantages of B-tree indices are: 
\begin{itemize}
  \item May use less tree nodes than a corresponding B$^{+}$-tree
  \item Sometimes possible to find search-key value before reaching leaf node 
\end{itemize}
Some disadvantages of B-tree indices are: 
\begin{itemize}
  \item Only small fraction of all search-key values are found correctly
  \item Non-leaf nodes are larger, so fan-out is reduced. Thus, B-trees typically have greater depth than corresponding B$^{+}$-tree 
  \item Insertion and deletion are more complicated than in B$^{+}$-trees 
  \item Implementation is harder than B$^{+}$-trees 
\end{itemize}
Typically, the advantages of B-Trees do not out weigh the disadvantages. 

\define{Covering indices} refers to adding extra attributes to an index so (some) queries can avoid fetching the actual records. If a record moves, all secondary indices that store record pointers have to be updated. Node splits in B$^{+}$-tree file organizations become very expensive; the solution is to use primary-index search keys instead of record pointers in secondary index. 

\section{Hashing}

A \define{bucket} is a unit of storage containing one or more records (a bucket is typically a disk block). In a \define{hash file organization} we obtain a bucket of a record directly from its search-key value using a \bold{hash function}. Hash function $h$ is a function from the set of all search-key values $K$ to the set of all bucket addresses $B$. Hash function is used to locate records for access, insertion as well as deletion. 

\begin{remark}
  Records with different search-key values may be mapped to the same bucket; thus entire bucket has to be searched sequentially to locate a record.
\end{remark}

An ideal hash function is \bold{uniform}, i.e., each bucket is assigned the same number of search-key values from the set of all possible values. Ideal hash function is \bold{random}, so each bucket will have the same number of records assigned to it irrespective of the actual distribution of search-key values in the file. \\ 

Bucket overflow can occur because of\dots 
\begin{itemize}
  \item Insufficient buckets 
  \item Skew in distribution of records 
\end{itemize}
Although the probability of bucket overflow can be reduced, it cannot be eliminated; it is handled by using \emph{overflow buckets}. In \define{closed hashing} (overflow chaining), the overflow buckets of a given bucket are chained together in a linked list (when bucket is full, just chain/link to a new bucket). An alternative, called \define{closed hashing}, which does not use overflow buckets, is not suitable for database applications.  

\subsection{Bitmap Indices}

Bitmap indices are a special type of index designed for efficient querying on multiple keys. Records in a relation are assumed to be numbered sequentially from say, 0. Given a number $n$ it must be easy to retrieve record $n$; particularly easy if records are of fixed size. This is applicable on attributes that take on a relatively small number of distinct values. A bitmap is simply an array of bits. \\

In its simplest form, a bitmap index on an attribute has a bitmap for each value of th attribute. The bitmap has as many bits as records. In a bitmap for value $v$, the bit for a record is 1 if the record has the value $v$ for the attribute, and is 0 otherwise.  

\begin{remark}
  To find the number (and location) of records that have two specific attributes, then we \bold{and} together the two bitmaps for each attribute and the resulting bit map will have ones in the locations of every record that shares both those attributes. E.g. all zeroes in the resulting bitmap would indicate that there are no records which have both of those attributes. 
\end{remark}

\begin{remark}
  Bitmaps work very well when the \bold{cardinality is low} (i.e. each attribute only has a few possible values that it can take on). If attributes include gender, country, or similar values that don't have many unique values; then a bitmap is an appropriate option. 
\end{remark}

\section{Query Processing}

The basic stpes in query processing are \bold{parsing and translation}, \bold{optimization}, and \bold{evaluation}. 

\subsection{Optimization}

A relational algebra expression may have many equivalent expressions. Each relational algebra operation can be evaluated using one of several different algorithms. Correspondingly, a relational-algebra expression can be evaluated in many ways. Annotates expression specifying detailed evaluation strategy is called an \define{evaluation-plan}. \\ 

Amongst all equivlaent evaluation plans, chosoe the one with the lowest cost. Cost is estimated using statistical information about the database. 

\subsubsection{Measures of Cost}

Cost is generally measured as total elapsed time for answering query. Typically disk access is the predominant cost, and is also relatively easy to estimate. This is measured by taking into account 
\begin{itemize}
  \item Number of seeks times average seek-cost
  \item Number of blocks read times average block read cost 
  \item Number of blocks written times average block write cost
\end{itemize}

\begin{remark}
  The cost to write a block is greater than the cost to read a block. Data is read back after being written to ensure that the write was successful. 
\end{remark}

Consider that $t_T$ is the time to transfer one block and $t_S$ is the time for one seek. Thus, the cost for one $b$ block transfers plus $S$ seeks is $b \times t_T + S \times t_S$. 

\subsection{Selection Operation}

\define{File scan} are search algorithms that locate and retrieve records that fulfill a selection condition. Algorithm \bold{A1} (linear search) will scan each file block and test all records to see whether they satisfy the selection condition. The cost estimate for linear search is $b_r$ block transfers + 1 seek ($b_r$ denotes the number of blocks contianing records from relation $r$). If selection is on a key attribute, can stop on finding record. Linear search can be applied regadless of selection condition, ordering of records in the file, or availability of indices. \\ 

\bold{A2} (binary search) is applicable if an equality comparison on the attribute on which file is ordered. Assume that the blocks of a relation are stored contiguously. The cost estimate (number of blocks to be scanned) is the $\ceil{\textrm{log}_2 (b_r)} \times (t_T + t_S)$. \\ 

\define{Index scan} are search algorithms that use an index. The selection condition must be on search-key of index.\\

In \bold{A3} (primary index on candidate key, equality), retrieve a single record that satisfies the corresponding equality condition $$\textrm{Cost} = (h_i + 1) \times (t_T + t_S)$$ where $h_i$ is the height of the index. \\ 

In \bold{A4} (primary index on nonkey, equality), retrieve multiple records. Records will be on consecutive blocks. Let $b$ = number of blocks containing matching records $$\textrm{Cost} = h_i \times (t_T + t_S) + t_S + t_T \times b$$ \\ 

In \bold{A5} (equality on serach-key of secondary index), retrieve a single record if the sarch-key is a candidate key $$\textrm{Cost} = (h_i + 1) \times (t_T + t_S)$$ Retrieve multiple records if search-key is not a candidate key. Each of $n$ matching records may be on a different $$\textrm{Cost} = (h_i + n) \times (t_T + t_S)$$ \\ 

In \bold{A6} (primary index, comparison) (Relation is sorted on A)\dots For $\sigma_{A \geq v}(r)$ use index to find first tuples $\geq v$ and scan relation sequentially from there. For $\sigma_{A \leq v}(r)$ just scan relation sequentially until the first tuple $> v$; do not use index. \\ 

In \bold{A7} (secondary index, comparison)\dots For $\sigma_{A \geq v}(r)$ use index to find first index entry $geq v$ and scan index sequentially from there, to find pointers to records. For $\sigma_{A \leq  v}(r)$ just scan leaf pages of index finding pointers to records, until first entry $> v$. In either case, retrieve records that are pointed to 
\begin{itemize}
  \item requires an I/O for each record 
  \item Linear file scan may be cheapter (use second index iff very few records are selected). 
\end{itemize}

\bold{Conjunction} is when there are multiple conditions to check for. In \bold{A8} (conjunctive selection using one index), select a combination of $\theta_i$ and algorithms A1 through A7 that results in the least cost for $\sigma_{\theta i}(r)$. Test other conditions on tuple after fetching it into memory buffer. \\

In \bold{A9} (conjunctive selection using multiple-key index), use appropriate composite (multiple-key) index if available. \\ 

\bold{A10} (conjunctive selection by intersection of identifiers) requires indices with record pointers. Use corresponding index for each condition and take intersection of all the obtained sets of record pointers. Then fetch records from file. If some conditions do not have appropriate indices, apply test in memory. \\ 

\bold{Disjunction} is when there are multiple conditions \emph{or}ed together. \bold{A11} (disjunctive selection by union of identifiers) is applicable if all conditions have available indices, otherwise use linear scan. Use corresponding index for each condition, and take union of all the obtained sets of record pointers. Then fetch records from file. When \bold{negation} is present, use linear scan on file. 

\subsection{Join Operations}

There are several different algorithms that can be used to implement joins 
\begin{itemize}
  \item Nested-loop join 
  \item Block nested-loop join 
  \item Indexed nested-loop join 
  \item Merge-join 
  \item Hash-join
\end{itemize}
The choice should be made based on cost estimate. \\ 

\subsubsection{Nested-Loop Join}

In the worst case, if there is enough memory only to hold one block of each relation, the estimated cost is $$n_r \times b_s + b_r$$ block transfers, plus $$n_r + b_r$$ seeks. If the smaller relation fits entirely in memory, use that as the inner relation. This reduces the cost to $b_r + b_s$ block transfers and 2 seeks. \\ 

\subsubsection{Block Nested-Loop Join}

\define{Block Nested-Loop Join} is a variant of nest-loop join in which every block of inner relation is paired with every block of outer relation. The worst case estimate is $b_r \times b_s + b_r$ block transfers $+ 2 \times b_r$ seeks. Each block in the inner relation is read once for each block in the outer relation (instead of once for each tuples in the outer relation). The best case is $b_r + b_s$ block transfers $+ 2$ seeks. For each tupel $t_r$ in the outer relation $r$, use the index to look up tuples in $s$ that satisfy the join condition with tuple $t_r$. 


\end{document}
